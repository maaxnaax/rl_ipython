{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of VWAP_Env.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpN7kl3VcFez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e435a306-3593-449e-e864-f298b0e574ba"
      },
      "source": [
        "!pip install ta\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "import ta\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ta\n",
            "  Downloading https://files.pythonhosted.org/packages/92/ba/5b69e3347a749f18110ceefdc8165aee12645b0c85f660db141828f72f5e/ta-0.5.11.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.17.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (0.25.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->ta) (1.12.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.5.11-cp36-none-any.whl size=23029 sha256=7f27763b17606f1888061d480bb3bcbe4378928c2cb0e24ffb244167fa98a2fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/32/1d/cbc724a8ecaec6e426baf57ab8c4c2cdc687aadd7427280b1f\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.5.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74MPxUBOcl75",
        "colab_type": "code",
        "outputId": "a28af2f0-289d-478a-ea52-2964929ff6d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# get data from google drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO-R48OUgbT6",
        "colab_type": "code",
        "outputId": "eb87e88c-1e4d-4e97-e4a3-bb165dd39a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Preprocessing the data into a list of days with rolling VWAP and miliseconds \n",
        "#   from midnight.\n",
        "# Notes:\n",
        "#   The VWAP is calculated using the Closing price because of the 5min \n",
        "#   granularity of the data. More fine grain data is needed.\n",
        "\n",
        "colnames=['Date', 'Time', 'Open','High', 'Low', 'Close', 'Volume'] \n",
        "data =  pd.read_csv('/content/gdrive/My Drive/TensorTrade_VWAP/ALSI5M.txt',\n",
        "                    sep = ','  , names=colnames, header=None)\n",
        "data[['Open','High', 'Low', 'Close', 'Vol']] = data[['Open','High', 'Low', 'Close', 'Volume']].apply(pd.to_numeric)\n",
        "# data.head()\n",
        "# def calc_rolling_VWAP(in_data):\n",
        "df = data.iloc[246132 : len(data[['Volume']]), ]\n",
        "df['VbyC'] = df['Close']*df['Volume']\n",
        "df['logged_and_diffed'] = (np.log(df['Close']) - np.log(df['Close'].shift(1)))*1000\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Vol</th>\n",
              "      <th>VbyC</th>\n",
              "      <th>logged_and_diffed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>246132</th>\n",
              "      <td>2009/09/17</td>\n",
              "      <td>08:34:53</td>\n",
              "      <td>23472</td>\n",
              "      <td>23650</td>\n",
              "      <td>23472</td>\n",
              "      <td>23650</td>\n",
              "      <td>41</td>\n",
              "      <td>41</td>\n",
              "      <td>969650</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246133</th>\n",
              "      <td>2009/09/17</td>\n",
              "      <td>08:39:37</td>\n",
              "      <td>23650</td>\n",
              "      <td>23700</td>\n",
              "      <td>23649</td>\n",
              "      <td>23700</td>\n",
              "      <td>74</td>\n",
              "      <td>74</td>\n",
              "      <td>1753800</td>\n",
              "      <td>2.111933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246134</th>\n",
              "      <td>2009/09/17</td>\n",
              "      <td>08:44:12</td>\n",
              "      <td>23700</td>\n",
              "      <td>23700</td>\n",
              "      <td>23680</td>\n",
              "      <td>23680</td>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "      <td>1278720</td>\n",
              "      <td>-0.844238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246135</th>\n",
              "      <td>2009/09/17</td>\n",
              "      <td>08:49:53</td>\n",
              "      <td>23680</td>\n",
              "      <td>23727</td>\n",
              "      <td>23680</td>\n",
              "      <td>23727</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>450813</td>\n",
              "      <td>1.982830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246136</th>\n",
              "      <td>2009/09/17</td>\n",
              "      <td>08:54:40</td>\n",
              "      <td>23740</td>\n",
              "      <td>23745</td>\n",
              "      <td>23725</td>\n",
              "      <td>23725</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>1115075</td>\n",
              "      <td>-0.084296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Date      Time   Open  ...  Vol     VbyC  logged_and_diffed\n",
              "246132  2009/09/17  08:34:53  23472  ...   41   969650                NaN\n",
              "246133  2009/09/17  08:39:37  23650  ...   74  1753800           2.111933\n",
              "246134  2009/09/17  08:44:12  23700  ...   54  1278720          -0.844238\n",
              "246135  2009/09/17  08:49:53  23680  ...   19   450813           1.982830\n",
              "246136  2009/09/17  08:54:40  23740  ...   47  1115075          -0.084296\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XD-wNvGwGl9",
        "colab_type": "code",
        "outputId": "ce6e2c56-e34f-4b88-cc93-f1dd3433df16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# getting miliseconds from midniight column\n",
        "def get_sec(time_str):\n",
        "    \"\"\"Get Seconds from time.\"\"\"\n",
        "    h, m, s = time_str.split(':')\n",
        "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
        "\n",
        "\n",
        "df['Msec'] = df['Time'].apply(get_sec)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiP3BCBYZZQH",
        "colab_type": "code",
        "outputId": "522d8881-5f62-4bbb-f84d-5e8c57465164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# # !pip install ta\n",
        "# import ta\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "diff = lambda x, y: x - y\n",
        "abs_diff = lambda x, y: abs(x - y)\n",
        "\n",
        "\n",
        "indicators = [\n",
        "  ('RSI', ta.momentum.rsi, ['Close']),\n",
        "  ('MFI', ta.momentum.money_flow_index, ['High', 'Low', 'Close', 'Volume']),\n",
        "  ('TSI', ta.momentum.tsi, ['Close']),\n",
        "  ('UO', ta.momentum.uo, ['High', 'Low', 'Close']),\n",
        "  ('AO', ta.momentum.ao, ['High', 'Close']),\n",
        "  ('MACDDI', ta.trend.macd_diff, ['Close']),\n",
        "  ('VIP', ta.trend.vortex_indicator_pos, ['High', 'Low', 'Close']),\n",
        "  ('VIN', ta.trend.vortex_indicator_neg, ['High', 'Low', 'Close']),\n",
        "  ('VIDIF', abs_diff, ['VIP', 'VIN']),\n",
        "  ('TRIX', ta.trend.trix, ['Close']),\n",
        "  ('MI', ta.trend.mass_index, ['High', 'Low']),\n",
        "  ('CCI', ta.trend.cci, ['High', 'Low', 'Close']),\n",
        "  ('DPO', ta.trend.dpo, ['Close']),\n",
        "  ('KST', ta.trend.kst, ['Close']),\n",
        "  ('KSTS', ta.trend.kst_sig, ['Close']),\n",
        "  ('KSTDI', diff, ['KST', 'KSTS']),\n",
        "  ('ARU', ta.trend.aroon_up, ['Close']),\n",
        "  ('ARD', ta.trend.aroon_down, ['Close']),\n",
        "  ('ARI', diff, ['ARU', 'ARD']),\n",
        "  ('BBH', ta.volatility.bollinger_hband, ['Close']),\n",
        "  ('BBL', ta.volatility.bollinger_lband, ['Close']),\n",
        "  ('BBM', ta.volatility.bollinger_mavg, ['Close']),\n",
        "  ('BBHI', ta.volatility.bollinger_hband_indicator, ['Close']),\n",
        "  ('BBLI', ta.volatility.bollinger_lband_indicator, ['Close']),\n",
        "  ('KCHI', ta.volatility.keltner_channel_hband_indicator, ['High', 'Low', 'Close']),\n",
        "  ('KCLI', ta.volatility.keltner_channel_lband_indicator, ['High', 'Low', 'Close']),\n",
        "  ('DCHI', ta.volatility.donchian_channel_hband_indicator, ['Close']),\n",
        "  ('DCLI', ta.volatility.donchian_channel_lband_indicator, ['Close']),\n",
        "  ('ADI', ta.volume.acc_dist_index, ['High', 'Low', 'Close', 'Volume']),\n",
        "  ('OBV', ta.volume.on_balance_volume, ['Close', 'Volume']),\n",
        "  ('CMF', ta.volume.chaikin_money_flow, ['High', 'Low', 'Close', 'Volume']),\n",
        "  ('FI', ta.volume.force_index, ['Close', 'Volume']),\n",
        "  ('EM', ta.volume.ease_of_movement, ['High', 'Low', 'Close', 'Volume']),\n",
        "  ('VPT', ta.volume.volume_price_trend, ['Close', 'Volume']),\n",
        "  ('NVI', ta.volume.negative_volume_index, ['Close', 'Volume']),\n",
        "  ('DR', ta.others.daily_return, ['Close']),\n",
        "  ('DLR', ta.others.daily_log_return, ['Close'])\n",
        "  ]\n",
        "\n",
        "\n",
        "def add_indicators(df) -> pd.DataFrame:\n",
        "    for name, f, arg_names in indicators:\n",
        "        wrapper = lambda func, args: func(*args)\n",
        "        args = [df[arg_name] for arg_name in arg_names]\n",
        "        df[name] = wrapper(f, args)\n",
        "    df.fillna(method='bfill', inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Here we add all of th indicators and two all zero columns to later be used\n",
        "#  for A_VWAP, and A_vol_left:\n",
        "df = add_indicators(df)\n",
        "df['zzz_A_VWAP'] = 0\n",
        "df['zzz_A_vol_left'] = 0\n",
        "\n",
        "\n",
        "\n",
        "#.reset_index())\n",
        "# df = dataframes[1]\n",
        "\n",
        "# df['logged_and_diffed'] = np.log(df['Close']) - np.log(df['Close'].shift(1))\n",
        "# # ##len(dataframes)\n",
        "# # ##checking that VWAP calculations are correct with a plot\n",
        "# day = -2\n",
        "# import matplotlib.pyplot as plt \n",
        "# a = df['logged_and_diffed']\n",
        "# b = df['Close']\n",
        "# x = range(len(b))\n",
        "# # plotting the points \n",
        "# plt.subplot(1, 2, 1) \n",
        "# plt.plot(x, b) \n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.plot(x,a)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4259: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  **kwargs\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8gBYhDeRuKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = np.array([df.iloc[4]])\n",
        "# len(df.iloc[4])\n",
        "# a[:,-2] = 420.69\n",
        "# a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8sVmR7ppSH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ======== GROUPING DAYS ==========\n",
        "grouped = df.groupby('Date')\n",
        "dataframes = [group for _, group in grouped]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5lqFMoLU6-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9y0yC0Diiwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rolling vwap\n",
        "def calc_rolling_vwap(data_frame):\n",
        "  data = np.cumsum(data_frame[['Vol']]) \n",
        "  data['rolling_VbyC'] = np.cumsum(data_frame[['VbyC']])\n",
        "  # = rolling_VbyC.div( rolling_volume,axis = 0)\n",
        "  #return VWAP\n",
        "  return round(data['rolling_VbyC']/data['Vol'])\n",
        "\n",
        "for i in range(len(dataframes)):\n",
        "  dataframes[i]['VWAP'] = calc_rolling_vwap(dataframes[i])\n",
        "  dataframes[i]['VWAP_Close_Diff'] = dataframes[i]['VWAP'] - dataframes[i]['Close']\n",
        "  dataframes[i] = dataframes[i].loc[:, dataframes[i].columns != 'Date']\n",
        "  dataframes[i] = dataframes[i].loc[:, dataframes[i].columns != 'Time']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpLstjiv2GQa",
        "colab_type": "code",
        "outputId": "4f94cb3e-b924-42f9-fc8e-634fb9b9a218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# ##len(dataframes)\n",
        "# ##checking that VWAP calculations are correct with a plot\n",
        "day = 9\n",
        "import matplotlib.pyplot as plt \n",
        "a = dataframes[day]['VWAP']\n",
        "b = dataframes[day]['Close']\n",
        "x = range(len(b))\n",
        "# plotting the points  \n",
        "plt.plot(x, b) \n",
        "plt.plot(x,a)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f11b3707470>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSimFBgOllFLA/wM9UFuEKEaYQQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOwi95KwISP1",
        "colab_type": "code",
        "outputId": "3104fab9-1663-4c4f-df64-4513d970f04c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "# take out the first and last trading days\n",
        "\n",
        "dataframes.pop()\n",
        "dataframes.pop(0)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Vol</th>\n",
              "      <th>VbyC</th>\n",
              "      <th>logged_and_diffed</th>\n",
              "      <th>Msec</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MFI</th>\n",
              "      <th>TSI</th>\n",
              "      <th>UO</th>\n",
              "      <th>AO</th>\n",
              "      <th>MACDDI</th>\n",
              "      <th>VIP</th>\n",
              "      <th>VIN</th>\n",
              "      <th>VIDIF</th>\n",
              "      <th>TRIX</th>\n",
              "      <th>MI</th>\n",
              "      <th>CCI</th>\n",
              "      <th>DPO</th>\n",
              "      <th>KST</th>\n",
              "      <th>KSTS</th>\n",
              "      <th>KSTDI</th>\n",
              "      <th>ARU</th>\n",
              "      <th>ARD</th>\n",
              "      <th>ARI</th>\n",
              "      <th>BBH</th>\n",
              "      <th>BBL</th>\n",
              "      <th>BBM</th>\n",
              "      <th>BBHI</th>\n",
              "      <th>BBLI</th>\n",
              "      <th>KCHI</th>\n",
              "      <th>KCLI</th>\n",
              "      <th>DCHI</th>\n",
              "      <th>DCLI</th>\n",
              "      <th>ADI</th>\n",
              "      <th>OBV</th>\n",
              "      <th>CMF</th>\n",
              "      <th>FI</th>\n",
              "      <th>EM</th>\n",
              "      <th>VPT</th>\n",
              "      <th>NVI</th>\n",
              "      <th>DR</th>\n",
              "      <th>DLR</th>\n",
              "      <th>zzz_A_VWAP</th>\n",
              "      <th>zzz_A_vol_left</th>\n",
              "      <th>VWAP</th>\n",
              "      <th>VWAP_Close_Diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>246132</th>\n",
              "      <td>23472</td>\n",
              "      <td>23650</td>\n",
              "      <td>23472</td>\n",
              "      <td>23650</td>\n",
              "      <td>41</td>\n",
              "      <td>41</td>\n",
              "      <td>969650</td>\n",
              "      <td>2.111933</td>\n",
              "      <td>30893</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>32.131314</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>37.382263</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.726621</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.004876</td>\n",
              "      <td>0.006616</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>14485.847720</td>\n",
              "      <td>-379.848583</td>\n",
              "      <td>-379.848583</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23650.000000</td>\n",
              "      <td>23650.000000</td>\n",
              "      <td>23650.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>41</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-3577.469962</td>\n",
              "      <td>2.442405e+07</td>\n",
              "      <td>-15.578500</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>-37.984858</td>\n",
              "      <td>0.211193</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23650.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246133</th>\n",
              "      <td>23650</td>\n",
              "      <td>23700</td>\n",
              "      <td>23649</td>\n",
              "      <td>23700</td>\n",
              "      <td>74</td>\n",
              "      <td>74</td>\n",
              "      <td>1753800</td>\n",
              "      <td>2.111933</td>\n",
              "      <td>31177</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>32.131314</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>37.382263</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.726621</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.004876</td>\n",
              "      <td>0.006616</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>14460.847720</td>\n",
              "      <td>-379.193032</td>\n",
              "      <td>-379.520807</td>\n",
              "      <td>0.327776</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23725.000000</td>\n",
              "      <td>23625.000000</td>\n",
              "      <td>23675.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>115</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-3577.469962</td>\n",
              "      <td>2.442405e+07</td>\n",
              "      <td>-15.417344</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.211416</td>\n",
              "      <td>0.211193</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23682.0</td>\n",
              "      <td>-18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246134</th>\n",
              "      <td>23700</td>\n",
              "      <td>23700</td>\n",
              "      <td>23680</td>\n",
              "      <td>23680</td>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "      <td>1278720</td>\n",
              "      <td>-0.844238</td>\n",
              "      <td>31452</td>\n",
              "      <td>69.892473</td>\n",
              "      <td>32.131314</td>\n",
              "      <td>99.115044</td>\n",
              "      <td>37.382263</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.726621</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.004876</td>\n",
              "      <td>0.006616</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.920354</td>\n",
              "      <td>14459.181054</td>\n",
              "      <td>-379.149328</td>\n",
              "      <td>-379.396981</td>\n",
              "      <td>0.247653</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23717.762760</td>\n",
              "      <td>23635.570573</td>\n",
              "      <td>23676.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>61</td>\n",
              "      <td>0.360947</td>\n",
              "      <td>-3577.469962</td>\n",
              "      <td>1.309122e+06</td>\n",
              "      <td>0.110879</td>\n",
              "      <td>999.156118</td>\n",
              "      <td>-0.084388</td>\n",
              "      <td>-0.084424</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23681.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246135</th>\n",
              "      <td>23680</td>\n",
              "      <td>23727</td>\n",
              "      <td>23680</td>\n",
              "      <td>23727</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>450813</td>\n",
              "      <td>1.982830</td>\n",
              "      <td>31793</td>\n",
              "      <td>82.912403</td>\n",
              "      <td>32.131314</td>\n",
              "      <td>98.415326</td>\n",
              "      <td>37.382263</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.726621</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.004876</td>\n",
              "      <td>0.006616</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.937073</td>\n",
              "      <td>14446.597720</td>\n",
              "      <td>-378.819368</td>\n",
              "      <td>-379.252578</td>\n",
              "      <td>0.433210</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23745.523884</td>\n",
              "      <td>23632.976116</td>\n",
              "      <td>23689.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.425532</td>\n",
              "      <td>-3577.469962</td>\n",
              "      <td>2.674169e+06</td>\n",
              "      <td>-0.007858</td>\n",
              "      <td>1001.139241</td>\n",
              "      <td>0.198480</td>\n",
              "      <td>0.198283</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23686.0</td>\n",
              "      <td>-41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246136</th>\n",
              "      <td>23740</td>\n",
              "      <td>23745</td>\n",
              "      <td>23725</td>\n",
              "      <td>23725</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>1115075</td>\n",
              "      <td>-0.084296</td>\n",
              "      <td>32080</td>\n",
              "      <td>81.301210</td>\n",
              "      <td>32.131314</td>\n",
              "      <td>97.760186</td>\n",
              "      <td>37.382263</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.726621</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.004876</td>\n",
              "      <td>0.006616</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.444444</td>\n",
              "      <td>14439.447720</td>\n",
              "      <td>-378.631880</td>\n",
              "      <td>-379.128438</td>\n",
              "      <td>0.496558</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23754.290932</td>\n",
              "      <td>23638.509068</td>\n",
              "      <td>23696.400000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>33</td>\n",
              "      <td>0.140426</td>\n",
              "      <td>-3577.469962</td>\n",
              "      <td>2.655427e+06</td>\n",
              "      <td>0.033749</td>\n",
              "      <td>1001.139241</td>\n",
              "      <td>-0.008429</td>\n",
              "      <td>-0.008430</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23694.0</td>\n",
              "      <td>-31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246235</th>\n",
              "      <td>23720</td>\n",
              "      <td>23720</td>\n",
              "      <td>23670</td>\n",
              "      <td>23700</td>\n",
              "      <td>136</td>\n",
              "      <td>136</td>\n",
              "      <td>3223200</td>\n",
              "      <td>-0.843526</td>\n",
              "      <td>61768</td>\n",
              "      <td>46.920650</td>\n",
              "      <td>42.408031</td>\n",
              "      <td>3.701498</td>\n",
              "      <td>49.513649</td>\n",
              "      <td>20.617647</td>\n",
              "      <td>-0.935754</td>\n",
              "      <td>0.930451</td>\n",
              "      <td>1.107143</td>\n",
              "      <td>0.176692</td>\n",
              "      <td>0.003211</td>\n",
              "      <td>25.643128</td>\n",
              "      <td>-55.525114</td>\n",
              "      <td>32.950000</td>\n",
              "      <td>0.946507</td>\n",
              "      <td>0.418358</td>\n",
              "      <td>0.528149</td>\n",
              "      <td>84.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>23772.311107</td>\n",
              "      <td>23661.788893</td>\n",
              "      <td>23717.050000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1174.296097</td>\n",
              "      <td>83</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>-1480.356196</td>\n",
              "      <td>-6.012658e+06</td>\n",
              "      <td>-0.085997</td>\n",
              "      <td>1005.107163</td>\n",
              "      <td>-0.084317</td>\n",
              "      <td>-0.084353</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23697.0</td>\n",
              "      <td>-3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246236</th>\n",
              "      <td>23700</td>\n",
              "      <td>23720</td>\n",
              "      <td>23700</td>\n",
              "      <td>23715</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>2774655</td>\n",
              "      <td>0.632711</td>\n",
              "      <td>62095</td>\n",
              "      <td>49.911664</td>\n",
              "      <td>37.500746</td>\n",
              "      <td>3.135582</td>\n",
              "      <td>49.741521</td>\n",
              "      <td>11.617647</td>\n",
              "      <td>-1.404642</td>\n",
              "      <td>0.923237</td>\n",
              "      <td>1.159751</td>\n",
              "      <td>0.236515</td>\n",
              "      <td>0.003119</td>\n",
              "      <td>25.563934</td>\n",
              "      <td>-21.889803</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.927650</td>\n",
              "      <td>0.565291</td>\n",
              "      <td>0.362359</td>\n",
              "      <td>80.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>23769.593912</td>\n",
              "      <td>23669.406088</td>\n",
              "      <td>23719.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1115.796097</td>\n",
              "      <td>200</td>\n",
              "      <td>0.031506</td>\n",
              "      <td>-1018.162454</td>\n",
              "      <td>1.265022e+06</td>\n",
              "      <td>-0.040621</td>\n",
              "      <td>1005.743306</td>\n",
              "      <td>0.063291</td>\n",
              "      <td>0.063271</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23697.0</td>\n",
              "      <td>-18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246237</th>\n",
              "      <td>23710</td>\n",
              "      <td>23750</td>\n",
              "      <td>23710</td>\n",
              "      <td>23744</td>\n",
              "      <td>213</td>\n",
              "      <td>213</td>\n",
              "      <td>5057472</td>\n",
              "      <td>1.222108</td>\n",
              "      <td>62368</td>\n",
              "      <td>55.171135</td>\n",
              "      <td>42.384687</td>\n",
              "      <td>4.253808</td>\n",
              "      <td>53.375001</td>\n",
              "      <td>7.370588</td>\n",
              "      <td>0.175708</td>\n",
              "      <td>0.975359</td>\n",
              "      <td>0.993840</td>\n",
              "      <td>0.018480</td>\n",
              "      <td>0.003205</td>\n",
              "      <td>25.536145</td>\n",
              "      <td>42.663477</td>\n",
              "      <td>-20.750000</td>\n",
              "      <td>1.071636</td>\n",
              "      <td>0.710116</td>\n",
              "      <td>0.361520</td>\n",
              "      <td>76.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>23771.966696</td>\n",
              "      <td>23669.533304</td>\n",
              "      <td>23720.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-966.696097</td>\n",
              "      <td>413</td>\n",
              "      <td>0.025830</td>\n",
              "      <td>9.717897</td>\n",
              "      <td>3.369272e+06</td>\n",
              "      <td>0.334519</td>\n",
              "      <td>1005.743306</td>\n",
              "      <td>0.122285</td>\n",
              "      <td>0.122211</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23697.0</td>\n",
              "      <td>-47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246238</th>\n",
              "      <td>23740</td>\n",
              "      <td>23800</td>\n",
              "      <td>23740</td>\n",
              "      <td>23784</td>\n",
              "      <td>245</td>\n",
              "      <td>245</td>\n",
              "      <td>5827080</td>\n",
              "      <td>1.683219</td>\n",
              "      <td>62694</td>\n",
              "      <td>61.219832</td>\n",
              "      <td>43.085506</td>\n",
              "      <td>7.240260</td>\n",
              "      <td>55.038668</td>\n",
              "      <td>17.300000</td>\n",
              "      <td>3.659229</td>\n",
              "      <td>1.003824</td>\n",
              "      <td>0.908222</td>\n",
              "      <td>0.095602</td>\n",
              "      <td>0.003730</td>\n",
              "      <td>25.630360</td>\n",
              "      <td>145.036331</td>\n",
              "      <td>-40.950000</td>\n",
              "      <td>1.316203</td>\n",
              "      <td>0.851859</td>\n",
              "      <td>0.464344</td>\n",
              "      <td>100.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>23780.566756</td>\n",
              "      <td>23671.333244</td>\n",
              "      <td>23725.950000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-852.362764</td>\n",
              "      <td>658</td>\n",
              "      <td>0.072703</td>\n",
              "      <td>1408.329626</td>\n",
              "      <td>1.009082e+07</td>\n",
              "      <td>0.673204</td>\n",
              "      <td>1005.743306</td>\n",
              "      <td>0.168464</td>\n",
              "      <td>0.168322</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23698.0</td>\n",
              "      <td>-86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246239</th>\n",
              "      <td>23790</td>\n",
              "      <td>23830</td>\n",
              "      <td>23780</td>\n",
              "      <td>23790</td>\n",
              "      <td>306</td>\n",
              "      <td>306</td>\n",
              "      <td>7279740</td>\n",
              "      <td>0.252239</td>\n",
              "      <td>62999</td>\n",
              "      <td>62.047060</td>\n",
              "      <td>49.340963</td>\n",
              "      <td>9.877963</td>\n",
              "      <td>52.269913</td>\n",
              "      <td>30.697059</td>\n",
              "      <td>5.974869</td>\n",
              "      <td>1.107807</td>\n",
              "      <td>0.845725</td>\n",
              "      <td>0.262082</td>\n",
              "      <td>0.004569</td>\n",
              "      <td>25.751441</td>\n",
              "      <td>191.930307</td>\n",
              "      <td>-41.450000</td>\n",
              "      <td>1.443016</td>\n",
              "      <td>0.979835</td>\n",
              "      <td>0.463181</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>23788.548074</td>\n",
              "      <td>23674.351926</td>\n",
              "      <td>23731.450000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1035.962764</td>\n",
              "      <td>964</td>\n",
              "      <td>0.072031</td>\n",
              "      <td>1469.425393</td>\n",
              "      <td>7.356032e+06</td>\n",
              "      <td>0.489931</td>\n",
              "      <td>1005.743306</td>\n",
              "      <td>0.025227</td>\n",
              "      <td>0.025224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23699.0</td>\n",
              "      <td>-91.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Open   High    Low  ...  zzz_A_vol_left     VWAP  VWAP_Close_Diff\n",
              "246132  23472  23650  23472  ...               0  23650.0              0.0\n",
              "246133  23650  23700  23649  ...               0  23682.0            -18.0\n",
              "246134  23700  23700  23680  ...               0  23681.0              1.0\n",
              "246135  23680  23727  23680  ...               0  23686.0            -41.0\n",
              "246136  23740  23745  23725  ...               0  23694.0            -31.0\n",
              "...       ...    ...    ...  ...             ...      ...              ...\n",
              "246235  23720  23720  23670  ...               0  23697.0             -3.0\n",
              "246236  23700  23720  23700  ...               0  23697.0            -18.0\n",
              "246237  23710  23750  23710  ...               0  23697.0            -47.0\n",
              "246238  23740  23800  23740  ...               0  23698.0            -86.0\n",
              "246239  23790  23830  23780  ...               0  23699.0            -91.0\n",
              "\n",
              "[108 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHEY_oEzdHNE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "630af276-509f-428a-8953-d16ec98caaec"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc7cCo4xctQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# =============================== MARKET Class ===============================\n",
        "# \n",
        "# MNH 2019\n",
        "#\n",
        "# This class must take in a list of dataframes.\n",
        "# \n",
        "# Each dataframe in the list is one trading day.\n",
        "# Each trading day is completely fresh and they are sampled at random everytime\n",
        "#   the environment is reset. (So that each episode of training is done on a \n",
        "#   unique day).\n",
        "# \n",
        "# The agent recieves Reward r only at the end of the trading day.\n",
        "# The Reward r is calculated as difference between the trading days VWAP, and \n",
        "#    the agents personal VWAP named A_VWAP.\n",
        "#\n",
        "# A possible alternative to explore using is a rolling sortino ratio, or just a\n",
        "#   rolling A_VWAP.\n",
        "#\n",
        "# --------------------- How the functions should work: --------------------\n",
        "#\n",
        "# 1.) env.reset():                                    Exmpl Values:\n",
        "# -----------------                                   ---------------------\n",
        "#   \n",
        "#   * Reseting the environment randomly selects a\n",
        "#       day from list_of_df, and resets the variables:\n",
        "#       reward, ind_in_day, A_VWAP, etc..\n",
        "#       \n",
        "#\n",
        "# 2.)   env.step():                                   Exmpl Values:\n",
        "# -----------------                                   ---------------------\n",
        "#\n",
        "#   * Keep track of period within the day.            ind_in_day += 1\n",
        "# \n",
        "#   * Take an Action a in the market.\n",
        "#\n",
        "#   * The action space is made up of N discrete \n",
        "#         choices.                                    a = 4    \n",
        "#\n",
        "#   * The agent buys volume a * trade_size at a price \n",
        "#         randomly sampled from the 5 min     \n",
        "#         interval from :  [Lowest_prc, HIghest_prc]                                      \n",
        "#\n",
        "#   * Keep track of the agents volume of trades.      A_Vol= 0 + a * trade_size\n",
        "#\n",
        "#   * Keep track of how many shares the agent still \n",
        "#         needs to buy.                               A_trgt_vol = 1000 - A_Vol\n",
        "#\n",
        "#   * Keep track of the agents rolling VWAP: A_VWAP,\n",
        "#         calculated as:\n",
        "#                cumsum(purchs price * purchs vol)    A_VWAP = 0\n",
        "#   \n",
        "#   * Return the tuple: (state2=s2, reward=r, done)\n",
        "# \n",
        "#   * Reward is calculated as:\n",
        "#       * r = 0, if it is not the terminal state, \n",
        "#         the terminal state is the last 5 min \n",
        "#         window in the day.\n",
        "#       * r = EOD_VWAP - A_VWAP, if s = terminal state.\n",
        "#   \n",
        "# MNH 2019\n",
        "# \n",
        "# ============================ End Of MARKET Class ===========================\n",
        "#\n",
        "#   Things that still need to be adressed:\n",
        "#       * need to figure out how to properly scale the data.\n",
        "#       * need to sample some days to be used as test days.\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "class Market(gym.Env):\n",
        "    \"\"\"This env is for training a BUYING vwap beating algo, with \n",
        "    OpenAI gym reinforcemnt learning algorithms\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, list_of_df):\n",
        "        super(Market, self).__init__()\n",
        "\n",
        "        self.list_of_df = list_of_df\n",
        "        self.current_day = list_of_df[0]\n",
        "        self.reward_range = (-2147483647, 2147483647)\n",
        "        # self.A_Vol = 0\n",
        "        self.current_step = 0\n",
        "        self.last_ind_in_day = len(list_of_df[0]) - 1\n",
        "        # self.trade_size = 10\n",
        "        self.A_VWAP = 0\n",
        "        self.A_rolling_vol  = 0\n",
        "        self.A_rolling_price = 0\n",
        "        self.A_vol_left = 1000\n",
        "        self.reward = 0\n",
        "        self.done = False\n",
        "\n",
        "        # To keep track of the AGENTS VWAP:\n",
        "        self.cum_VbyP = 0\n",
        "        self.cum_vol_traded = 0\n",
        "        self.purchase_vol = 80\n",
        "\n",
        "\n",
        "        self.action_space =   spaces.Box(low=np.array([0, 0]), high=np.array([3, 1]), dtype=np.float16)\n",
        "        \n",
        "\n",
        "        # Prices contains the OHLC for the 5 min interval\n",
        "        # Miliseconds from midnight\n",
        "        # Rolling VWAP for this time period\n",
        "        # The agents Rolling VWAP, A_VWAP\n",
        "        # The Vol of securities left to still buy, A_trgt_vol\n",
        "        # The Vol traded this time step in the market\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-2147483647, high=2147483647, shape=(1, len(list_of_df[1].iloc[2])), dtype=np.float16)\n",
        "\n",
        "    def _take_action(self, a):\n",
        "\n",
        "        # Only buy if there are still shares to be bought today,\n",
        "        if (self.A_vol_left > 0):\n",
        "\n",
        "          # Purchase a * volume of a trade\n",
        "          vol = self.purchase_vol * a[0] \n",
        "          print(vol)\n",
        "          # But if there arent enough shares still to buy\n",
        "          if (vol > self.A_vol_left):\n",
        "            vol = self.A_vol_left\n",
        "          \n",
        "          self.A_vol_left = self.A_vol_left - vol\n",
        "\n",
        "          # Increase the volume of shares traded:\n",
        "          self.cum_vol_traded = self.cum_vol_traded + vol\n",
        "\n",
        "          if (vol > 0):\n",
        "            # Sample a random price between high and low for this interval:\n",
        "            price = round( random.uniform(self.current_day['Low'].iloc[self.current_step],\n",
        "                                  self.current_day['High'].iloc[self.current_step]))\n",
        "\n",
        "            # Update cumulative price multiplied by volume:\n",
        "            self.cum_VbyP = self.cum_VbyP + (vol * price)\n",
        "            # Update the Agents VWAP, A_VWAP\n",
        "            self.A_VWAP = self.cum_VbyP / self.cum_vol_traded\n",
        "          \n",
        "    def _next_observation(self):\n",
        "\n",
        "\n",
        "        frame = np.array([ self.current_day.iloc[self.current_step]])\n",
        "        frame[:,-1] = self.A_VWAP\n",
        "        frame[:,-2] = self.A_vol_left\n",
        "\n",
        "        return frame\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        # Execute one time step within the environment\n",
        "        print(action)\n",
        "        self._take_action(action)\n",
        "\n",
        "        self.current_step += 1\n",
        "\n",
        "\n",
        "        reward = 0 # always return zero until the last day\n",
        "        if (self.current_step==self.last_ind_in_day):\n",
        "          if(self.A_vol_left<1):\n",
        "            reward = self.current_day['VWAP'].iloc[self.current_step] - self.A_VWAP\n",
        "          else: reward =-999999\n",
        "          self.done = True\n",
        "\n",
        "\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        return obs, reward, self.done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the state of the environment to an initial random day\n",
        "        ind = random.randrange(0,len(self.list_of_df))\n",
        "        self.current_day = self.list_of_df[ind]\n",
        "\n",
        "        # Set the current step to a random point within the data frame\n",
        "        self.current_step = 1\n",
        "        # self.last_ind_in_day = len(self.list_of_df[0]) - 1\n",
        "        self.A_VWAP = 0\n",
        "        self.A_rolling_vol  = 0\n",
        "        self.A_rolling_price = 0\n",
        "        self.A_vol_left = 1000\n",
        "        self.reward = 0\n",
        "        self.done = False\n",
        "        self.last_ind_in_day = len(self.list_of_df[ind]) - 1\n",
        "\n",
        "        # To keep track of the AGENTS VWAP:\n",
        "        self.cum_VbyP = 0\n",
        "        self.cum_vol_traded = 0\n",
        "\n",
        "        return self._next_observation()\n",
        "\n",
        "\n",
        "# ====================== End of MARKET class =======================\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8vzc7kncxmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slice_point = int(len(dataframes) - len(dataframes)/3*2)\n",
        "train_df = dataframes[:slice_point]\n",
        "test_df = dataframes[slice_point:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBisb-N5YN3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, MlpLnLstmPolicy, CnnLnLstmPolicy, CnnPolicy, CnnLstmPolicy\n",
        "from stable_baselines.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
        "from stable_baselines import PPO2, A2C\n",
        "# from gym.wrappers import Monitor\n",
        "from stable_baselines.bench import Monitor\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_env = DummyVecEnv([lambda: Market(train_df)])\n",
        "test_env = DummyVecEnv([lambda: Market(test_df)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X3SlQIAYUji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = PPO2(MlpPolicy,#MlpLstmPolicy,\n",
        "#              train_env,\n",
        "#              verbose=1, \n",
        "#              tensorboard_log=\"./tensorboard/\")\n",
        "# model.learn(total_timesteps=108)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xObyT1iZnNY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model,env):\n",
        "\n",
        "\n",
        "  rewards_l = []\n",
        "  actions = []\n",
        "  for i in range(20):\n",
        "    done = False\n",
        "    obs = env.reset()\n",
        "    while not done:\n",
        "      action, _states = model.predict(obs)\n",
        "      obs, rewards, done, info = env.step(action)\n",
        "      actions.append(action)\n",
        "\n",
        "      # print(rewards)\n",
        "      # print(rewards)\n",
        "    rewards_l.append(rewards)\n",
        "    print(actions)\n",
        "\n",
        "  return np.mean(rewards_l), np.std(rewards_l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rQMK3jodAnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "415279cc-5ddf-440f-c779-049edc58a764"
      },
      "source": [
        "\n",
        "model = PPO2('MlpLstmPolicy', train_env, nminibatches=1, verbose=0)\n",
        "n_stepss = 2000\n",
        "for i in range(1000):\n",
        "  model.learn(n_stepss)\n",
        "  rewa , sig = test_model(model,test_env)\n",
        "  print(\"=================================================================\")\n",
        "  print('Num steps trained:')\n",
        "  a = (i+1)*n_stepss\n",
        "  print(a)\n",
        "  print(\"=================================================================\")\n",
        "  print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "  print('The out of sample MEAN REWARD is:')\n",
        "  print(rewa)\n",
        "  print('The out of sample Standard deviation of REWARDs is:')\n",
        "  print(sig)\n",
        "  print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "  rewa , sig = test_model(model,train_env)\n",
        "  print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
        "  print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
        "  print('The IN sample MEAN REWARD is:')\n",
        "  print(rewa)\n",
        "  print('The IN sample Standard deviation of REWARDs is:')\n",
        "  print(sig)\n",
        "  print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
        "  print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
        "  model.save(\"/content/gdrive/My Drive/\" + 'VWAP_20000')\n",
        "  print('\\n')\n",
        "  print('\\n')\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "nan\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n",
            "[nan nan]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-bf491c89b585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_stepss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_stepss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mrewa\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=================================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, seed, log_interval, tb_log_name)\u001b[0m\n\u001b[1;32m    305\u001b[0m                             \u001b[0mmb_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmb_env_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                             mb_loss_vals.append(self._train_step(lr_now, cliprangenow, *slices, update=timestep,\n\u001b[0;32m--> 307\u001b[0;31m                                                                  writer=writer, states=mb_states))\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mloss_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_loss_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36m_train_step\u001b[0;34m(self, learning_rate, cliprange, obs, returns, masks, actions, values, neglogpacs, update, writer, states)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             policy_loss, value_loss, policy_entropy, approxkl, clipfrac, _ = self.sess.run(\n\u001b[0;32m--> 253\u001b[0;31m                 [self.pg_loss, self.vf_loss, self.entropy, self.approxkl, self.clipfrac, self._train], td_map)\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpolicy_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapproxkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipfrac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyj_P8MajmFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Visual validation\n",
        "\n",
        "# done = False\n",
        "#     obs = env.reset()\n",
        "#     while not done:\n",
        "#       action, _states = model.predict(obs)\n",
        "#       obs, rewards, done, info = env.step(action)\n",
        "#       #print(rewards)\n",
        "#       # print(rewards)\n",
        "\n",
        "# mrkt = Market(dataframes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIHyvpw0PkP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "done = False\n",
        "# obs = train_env.reset()\n",
        "# mrkt.action_space.sample()\n",
        "\n",
        "model.predict(obs)\n",
        "# while not done:\n",
        "#   action = 10 # random.randrange(int(0),int(10))\n",
        "#   obs, rewards, done, info = mrkt.step(action)\n",
        "  \n",
        "# print(rewards) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}